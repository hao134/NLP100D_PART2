{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "課程練習.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of5Mipcx9K9C"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aON6jWi59K9G"
      },
      "source": [
        "## nn.Module\n",
        "* Base class for all neural network modules\n",
        "* 只要在nn.Module的子類中定義了forward函數，backward函數就會被自動實現（利用Autograd）\n",
        "* nn.Conv2d 本身也是nn.Module的類別(此時我們可以先不用理解nn.Conv2D做了什麼，只需了解其包含一些參數與操作)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBFxw-vr9K9I"
      },
      "source": [
        "# class Model(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Model, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(1, 20, 5)\n",
        "#         self.conv2 = nn.Conv2d(20, 20, 5)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.conv1(x))\n",
        "#         return F.relu(self.conv2(x))\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,20,5)\n",
        "    self.conv2 = nn.Conv2d(20,20,5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    return F.relu(self.conv2(x))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhL_vxFr9K9I"
      },
      "source": [
        "model = Model()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkhUGkc_9K9J"
      },
      "source": [
        "### 實踐 forward propagation \n",
        "* 為什麼不應該直接call model.forward : https://discuss.pytorch.org/t/any-different-between-model-input-and-model-forward-input/3690"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jSJYASI9K9K",
        "outputId": "20275ed5-38f3-4605-f969-fc24b4a35c5d"
      },
      "source": [
        "input_ = torch.randn(1,1,124,124)\n",
        "output = model(input_)\n",
        "output.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 116, 116])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teYUwmY49K9L"
      },
      "source": [
        "### 查看 model 底下的 modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXJKmNzV9K9M"
      },
      "source": [
        "#### .modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgUcV7hT9K9N"
      },
      "source": [
        "* model.modules 遞迴的列出所有的 modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysOyDzSp9K9P",
        "outputId": "0d0e07bb-f4d9-4e3c-9828-e00cfaea0b7c"
      },
      "source": [
        "# for module in model.modules():\n",
        "#     print(module)\n",
        "for module in model.modules():\n",
        "  print(module)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            ")\n",
            "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GurH8OqZ9K9Q"
      },
      "source": [
        "#### .children"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBY3Eh0a9K9R"
      },
      "source": [
        "* model.children 只列出第一層的子 modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wMohp969K9R",
        "outputId": "7777eee2-d5e1-4a2f-93b1-52fb6eb0fb90"
      },
      "source": [
        "for module in model.children():\n",
        "    print(module)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUG1yfBd9K9S"
      },
      "source": [
        "### 查看 model 內的 parameters (torch.nn.parameter.Parameter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVV2uqYb9K9T"
      },
      "source": [
        "#### .named_parameters\n",
        "* named_parameters會列出每個nn.Module底下parameters 的名字,數值\n",
        "* 同時可以查看 requires_grad是否開啟(for backpropagation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmFMW0ZD9K9U",
        "outputId": "38850a90-d530-4c99-a7c3-101ff01d190c"
      },
      "source": [
        "# for name, param in model.named_parameters():\n",
        "#     print(name,param.requires_grad)\n",
        "#     #param.requires_grad=True\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "  print(name, param.requires_grad)\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.weight True\n",
            "conv1.bias True\n",
            "conv2.weight True\n",
            "conv2.bias True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdpxeASq9K9U"
      },
      "source": [
        "#### .parameters\n",
        "* 不會印出名字"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOyC1liM9K9V",
        "outputId": "5a7d6ae3-899e-49c9-c866-3c605f0fe902"
      },
      "source": [
        "for param in model.parameters():\n",
        "    print(type(param),param.shape, param.requires_grad)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.nn.parameter.Parameter'> torch.Size([20, 1, 5, 5]) True\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([20]) True\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([20, 20, 5, 5]) True\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([20]) True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nr31DAy9K9W"
      },
      "source": [
        "#### 計算模型可訓練參數總量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlAjw6ZV9K9X",
        "outputId": "391fd1c3-af45-417e-80aa-8ea677e865a2"
      },
      "source": [
        "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "# params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "# print('總共參數量：' ,params)\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print('總共參數量：' ,params)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "總共參數量： 10540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHxQ77Yu9K9Z"
      },
      "source": [
        "### Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTNmrhxt9K9Z"
      },
      "source": [
        "input_ = torch.randn(1,1,124,124)\n",
        "output = model(input_)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX7LJbfq9K9c"
      },
      "source": [
        "#### 確認 requires_grad為 True (default 就是 True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nNaxzO39K9c",
        "outputId": "8898786d-71ff-4f36-8c89-1fc185c5d1c2"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name,param.requires_grad)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.weight True\n",
            "conv1.bias True\n",
            "conv2.weight True\n",
            "conv2.bias True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB7rIHuz9K9d"
      },
      "source": [
        "#### 此時還沒做backpropagation，parameters沒有gradient value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJTALLrj9K9e",
        "outputId": "8f652d79-612c-4f14-cb18-533d63193a52"
      },
      "source": [
        "print(model.conv1.weight.grad)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TurLAyXj9K9f"
      },
      "source": [
        "#### 執行backward，完成後就能看到每個parameters底下的gradient value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7YOcusH9K9f"
      },
      "source": [
        "output.sum().backward()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfIb2VkQ9K9g",
        "outputId": "c618dd67-e9d0-475a-a027-6f3f54a6b4da"
      },
      "source": [
        "print(model.conv1.weight.grad)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[  522.9692,   454.4109,  -592.5370,   330.3468,   468.0063],\n",
            "          [ -529.6297,   927.8635,   665.0973,   162.6237,  -770.4840],\n",
            "          [  651.2021,  -190.9409,   553.1579,   650.3015,   284.0137],\n",
            "          [ -103.7130,  -786.4781,    46.0564,   613.2404,   328.7287],\n",
            "          [   28.6708,   196.4807,  -190.1977,   262.4489, -1008.4745]]],\n",
            "\n",
            "\n",
            "        [[[  379.6396,    15.3367,   -37.3638,    15.9327,    12.5054],\n",
            "          [  234.2216,   252.4350,   219.4751,   393.4599,  -257.3908],\n",
            "          [  -95.9540,   -46.5520,   280.6422,    62.3226,  -171.3840],\n",
            "          [ -228.7197,    16.7131,   418.8062,  -142.5411,     7.6002],\n",
            "          [ -323.3826,   377.8612,   126.3426,   -70.7429,   -81.7496]]],\n",
            "\n",
            "\n",
            "        [[[  844.4539,  -600.1066,  -520.8076,   769.9362, -1079.1150],\n",
            "          [  993.7142,  1268.3313, -1454.2256,  -703.0765,   120.9676],\n",
            "          [ -736.9225,   698.8443,   107.3563, -1214.4150,   -74.9459],\n",
            "          [ -977.1591,  -280.8511,   -29.4711,   217.3521,  -658.7909],\n",
            "          [ 1205.3364,   -41.1689, -1161.0159, -1176.6451,  -427.1440]]],\n",
            "\n",
            "\n",
            "        [[[  510.0397,   -28.8698,  -263.7697,  -273.6475,  -266.5232],\n",
            "          [    3.4757,  -694.6811,    40.2126,  -773.5280,   291.1989],\n",
            "          [  181.6210,   303.4465,    41.0120,   905.9065,  -588.9672],\n",
            "          [  559.6455,  -733.6115,   304.6901,   462.6927,   736.0771],\n",
            "          [ -731.0286,  -162.8680,    72.4889,  -274.2415,   585.4766]]],\n",
            "\n",
            "\n",
            "        [[[ -584.5986,   486.6305,  -907.2570,   747.8018,  -992.4875],\n",
            "          [  233.6131,  -127.3469,   100.7315,   649.9366,   743.5680],\n",
            "          [  795.3310,   866.4852,  -698.8651,   848.2388,   -43.6651],\n",
            "          [  543.7939,  1080.3024,   805.3970,   964.2598,   288.1574],\n",
            "          [ -770.5770,  -680.1039,   146.5557,   547.3637,   338.1991]]],\n",
            "\n",
            "\n",
            "        [[[ -421.8006,  -420.9759, -1762.3246,   938.5209,  -937.2385],\n",
            "          [ 1449.5653,  1507.1823,  1367.0881,  -810.2519, -1223.0844],\n",
            "          [ 1033.9354,  -997.3820, -1526.9067, -1401.4652, -1027.9955],\n",
            "          [ 1495.9578,    11.4241, -1265.1394,   780.3077,  -630.0359],\n",
            "          [ -211.4343,   266.7139,  1482.4139,  -585.8794,  -600.8189]]],\n",
            "\n",
            "\n",
            "        [[[ -562.8799,  -107.0816,   526.8669,  -195.6954,  -862.9698],\n",
            "          [  491.3600, -1169.2716,  1130.7098, -1542.9543,  -597.3899],\n",
            "          [  385.9323,  -737.9399,  -409.5213, -1042.9236,  -468.7455],\n",
            "          [-1390.9956,  -934.4510,  -238.4750,  1529.9814,  1141.2825],\n",
            "          [ 1348.0439,  -501.0677,   918.8159,  -318.6637,  1217.6545]]],\n",
            "\n",
            "\n",
            "        [[[ 1455.6698,   535.0648,  1312.9441,  -303.5732, -1348.2047],\n",
            "          [  256.2191,  -834.3180,   524.4880,  1039.8252,  -976.7072],\n",
            "          [ -316.9699,  1113.3037,  -870.7535, -1338.7688,  -238.2437],\n",
            "          [  156.3379,  1069.1887,  -102.9878, -1186.3579,   402.3325],\n",
            "          [ -710.0359,  -901.4118,  -465.6841,  -118.4001,  -587.7185]]],\n",
            "\n",
            "\n",
            "        [[[ 1566.0530,  -590.5818, -1754.5452,  -707.1710,  1397.0135],\n",
            "          [-1216.5620,  -969.2051,  1539.7349,  2059.8857,  -503.4427],\n",
            "          [ -579.4910, -1614.4414,  -300.3420,   789.2125,   397.5786],\n",
            "          [-1771.1920, -1656.6903,  -661.9058,  -525.4527,  -726.1873],\n",
            "          [ 1315.4554,  -636.5462, -1288.5808, -2064.1167,  -735.3910]]],\n",
            "\n",
            "\n",
            "        [[[ -136.0481,   -53.9972,   218.6544,   200.5145,    55.5887],\n",
            "          [   71.0645,    99.8156,   304.1616,   125.9537,   248.0546],\n",
            "          [  -93.0392,   -54.6394,    46.4503,  -176.3228,   -29.0067],\n",
            "          [ -139.4391,   -89.0550,    29.7172,  -252.0259,  -228.6652],\n",
            "          [  210.1845,    98.6310,   318.1129,   149.3612,  -199.6675]]],\n",
            "\n",
            "\n",
            "        [[[ 1059.3253, -1152.6116,  -653.7764,   599.4324,   446.9470],\n",
            "          [  210.7614,   -25.5342,  -423.3022,  1129.1982,  -158.3128],\n",
            "          [   60.9820,   824.0152,  1022.7574,  -122.2120,  -738.5182],\n",
            "          [ -312.0779,   987.7723,   338.7044,   643.6178,   510.3139],\n",
            "          [ 1244.4100,  -817.9561,  1410.4963,  -238.8876, -1332.4492]]],\n",
            "\n",
            "\n",
            "        [[[  152.4653,  -265.4023,   -59.7331,   -58.1385,   169.1027],\n",
            "          [  148.8150,    89.7063,  -157.4741,   609.2756,   264.2459],\n",
            "          [  484.4852,   503.4796,   134.5964,   172.7502,   467.5046],\n",
            "          [  196.8499,   126.3685,  -186.3152,   -92.4787,  -179.4247],\n",
            "          [  136.8551,   235.6890,    14.1793,   -95.2705,  -449.4350]]],\n",
            "\n",
            "\n",
            "        [[[ -449.0925,  -965.3425,  1265.3932,    35.6330,  -361.2382],\n",
            "          [  599.7126, -1699.4071,  1526.5527,   650.5296, -1389.2063],\n",
            "          [ -528.0314,   235.4371,   974.0862, -1085.6809,  -451.3924],\n",
            "          [  577.5306,    41.1668,  -310.3578,  -682.5414,  -141.4229],\n",
            "          [ 1585.5048,   414.7692,  1564.3105,  -161.4050,  -373.4626]]],\n",
            "\n",
            "\n",
            "        [[[-1127.0500,  -500.2034,     8.8873, -1239.3450,  -905.7964],\n",
            "          [  -15.0534,  -190.9239,   813.0449,   725.5511,   904.5728],\n",
            "          [  512.7991,   167.8797,  -674.6911,   635.6486,   -93.1414],\n",
            "          [ -527.0358,  -584.9463,  -537.3018,   343.4516,   604.0540],\n",
            "          [ -322.6873,   383.4873,  -647.8500,   -21.3593,  1125.9286]]],\n",
            "\n",
            "\n",
            "        [[[  133.7322,  -860.0385,   637.6841,   427.0405,   176.3764],\n",
            "          [  229.9277,  -311.6607,  1035.1191,  -541.8251,   310.1172],\n",
            "          [  -57.0835,  -421.1446,   149.4160,   262.0692,  -244.8434],\n",
            "          [  141.2829, -1144.1758,  1029.4771,  -157.0086,  1127.5663],\n",
            "          [-1170.0372,  -401.8681,  -866.1935, -1164.6521,  1294.9274]]],\n",
            "\n",
            "\n",
            "        [[[ 1068.7589,  1128.6096,   246.4673, -1911.8108,  -481.0966],\n",
            "          [ -301.6460,  -200.9914,  -483.3567,  -163.6237, -1594.4479],\n",
            "          [-1091.4453,  -700.0429,   620.8809,  -457.2466,  -638.6466],\n",
            "          [ 1221.3212,   164.6253,  -319.7369,  1704.8497,  1316.2576],\n",
            "          [-1392.2924,  -505.4757, -1715.9375,   569.1096,  -277.6245]]],\n",
            "\n",
            "\n",
            "        [[[  205.3870,    12.6754,   -10.7956,  -177.5706,   269.8025],\n",
            "          [ -711.0558,  -667.7051,   633.2014,  -475.8220,   385.3985],\n",
            "          [  657.0615,   670.4143,  -368.2298,   551.1781,  -846.8735],\n",
            "          [  756.6279,   617.9813,  -710.5044,  -210.6212,   671.5954],\n",
            "          [  -49.0264,  -564.4291,   524.9196,   300.2316,  -695.1530]]],\n",
            "\n",
            "\n",
            "        [[[  730.4417,   408.3203,   128.8320,    70.3577,   827.3391],\n",
            "          [ -869.6978,   158.1681,   -52.9773,  -335.3405,   110.7557],\n",
            "          [ -369.7153,   256.7455,  -223.8596,  -346.1486,   -92.9980],\n",
            "          [  956.8097,   567.0616,  -573.2894,  -624.6512,  -550.4207],\n",
            "          [  227.7342,   633.2893,   402.4026,  -438.6275,  -670.9270]]],\n",
            "\n",
            "\n",
            "        [[[ -431.3844,    82.1166,   207.3072,  -252.3072,  -498.5924],\n",
            "          [  -64.0734,   531.6493,   307.5486,  -444.0728,   470.6409],\n",
            "          [   85.9815,   342.8298,   674.6407,  -159.9809,  -517.5836],\n",
            "          [  520.5414,  -116.4775,  -327.5393,    22.7084,  -345.1161],\n",
            "          [ -735.3224,   330.8506,   563.2469,   -92.3079,  -250.0878]]],\n",
            "\n",
            "\n",
            "        [[[ -490.5171,   138.8414,   261.4117,  -774.7910,  -261.2695],\n",
            "          [ -270.5864,  -299.6434,  -327.2415,    65.3260,   501.0886],\n",
            "          [ -843.0139,  -182.9812,  -617.2122,   929.7880,  -239.0291],\n",
            "          [  259.3858,   113.3459,  -364.3107,  -565.5742,   -21.7091],\n",
            "          [ -402.8243,   511.0273,    71.5950,   548.0435,   232.6964]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX29ZPKW9K9g"
      },
      "source": [
        "#### 當我們把 parameters 的 requires_grad關閉時，就無法成功的完成backward\n",
        "* 什麼時候會關閉requires_grad關閉時？ prediction (inference)的階段\n",
        "* 設定 requires_grad = True 是為了之後要做 backpropagation，在計算每個paramters的 gradient時，我們在forward propagation時需要保留額外的訊息(根據chain rule)，這會導致記憶體使用量上升與計算速度下降，然而只有在 training 階段時我們材需要做backpropagation，在 prediction (inference)的階段，我們則可以設定 requires_grad = False 來提升速度與降低記憶體使用量 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTPZcWCN9K9j"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2utrYIa49K9j"
      },
      "source": [
        "input_ = torch.randn(1,1,124,124)\n",
        "output = model(input_)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "WK_GzN889K9k",
        "outputId": "ac823ab7-3bfa-445e-add9-e8727d8efc25"
      },
      "source": [
        "output.sum().backward()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d36a7f9dc350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eJzRuON9K9l"
      },
      "source": [
        "#### with torch.no_grad()\n",
        "* 此行底下的requires_grad都會關閉"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "vRbqMga79K9l",
        "outputId": "a0cd9d13-527e-49ca-8162-26e30f27af63"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "with torch.no_grad():\n",
        "    input_ = torch.randn(1,1,124,124)\n",
        "    output = model(input_)\n",
        "    output.sum().backward()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1f483c7eca92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m124\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m124\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA3HftDG9K9m"
      },
      "source": [
        "### 讓我們自行搭建一個 nn.Module 並試算gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tji6HwKG9K9m"
      },
      "source": [
        "# class Model(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Model, self).__init__()\n",
        "#         self.x = torch.nn.Parameter(torch.tensor(2.4,dtype=torch.float32))\n",
        "#         self.y = torch.nn.Parameter(torch.tensor(4.3,dtype=torch.float32))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         output = x*self.x**2 + x*self.y + x # 可以看成 output = w*x*x + w*y+2\n",
        "#         return output\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.x = torch.nn.Parameter(torch.tensor(2.4, dtype = torch.float32))\n",
        "    self.y = torch.nn.Parameter(torch.tensor(4.3, dtype = torch.float32))\n",
        "\n",
        "  def forward(self,x):\n",
        "    output = x * self.x**2 + x*self.y + x\n",
        "    return output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKPBPI1Z9K9n",
        "outputId": "a9e63164-3243-4036-866d-ce206a0d0e0e"
      },
      "source": [
        "model = Model()\n",
        "input_ = torch.tensor(1.3, dtype = torch.float32)\n",
        "output = model(input_)\n",
        "output.backward()\n",
        "# output 對 self.x 的偏微分為 2 * w * x = 2 * 1.3 * 2.4 = 6.24 \n",
        "print('self.x 的 gradient : {}'.format(model.x.grad))\n",
        "# output 對 self.y 的偏微分為 w = 1.3\n",
        "print('self.y 的 gradient : {}'.format(model.y.grad))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "self.x 的 gradient : 6.240000247955322\n",
            "self.y 的 gradient : 1.2999999523162842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ5Hv7gp9K9n"
      },
      "source": [
        "## Sequential\n",
        "* nn.Module 的容器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBlBsBd89K9o"
      },
      "source": [
        "# layer = nn.Sequential(\n",
        "#                         nn.Conv2d(3,\n",
        "#                                   20,\n",
        "#                                   kernel_size=3,\n",
        "#                                   stride=1,\n",
        "#                                   padding=1,\n",
        "#                                   bias=False), \n",
        "#                         nn.BatchNorm2d(20),\n",
        "#                         nn.LeakyReLU(inplace=True))\n",
        "\n",
        "layer = nn.Sequential(\n",
        "    nn.Conv2d(3,\n",
        "              20,\n",
        "              kernel_size = 3,\n",
        "              stride = 1,\n",
        "              padding = 1, \n",
        "              bias = False),\n",
        "    nn.BatchNorm2d(20),\n",
        "    nn.LeakyReLU(inplace=True)\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3nUrUzj9K9p",
        "outputId": "4078d5bf-3b8c-49e7-bc67-96b53c4d18ef"
      },
      "source": [
        "for name, param in layer.named_parameters():\n",
        "    print(name,param.requires_grad)\n",
        "    #param.requires_grad=True"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.weight True\n",
            "1.weight True\n",
            "1.bias True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFivBBOQ9K9q",
        "outputId": "e82d2cb3-4a46-44cd-a5f9-1a7711f2fc79"
      },
      "source": [
        "input_ = torch.randn(1, 3, 124, 124)\n",
        "output = layer(input_)\n",
        "output.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 124, 124])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkSOISor9K9q"
      },
      "source": [
        "#### OrderedDict+Sequential, 讓我們替每一個module命名"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD_aYehT9K9r"
      },
      "source": [
        "from collections import OrderedDict"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eB30zxo9K9r"
      },
      "source": [
        "# layer = nn.Sequential(OrderedDict([\n",
        "#           ('conv1', nn.Conv2d(1,20,5)),\n",
        "#           ('relu1', nn.ReLU()),\n",
        "#           ('conv2', nn.Conv2d(20,64,5)),\n",
        "#           ('relu2', nn.ReLU())\n",
        "#         ]))\n",
        "layer = nn.Sequential(OrderedDict([\n",
        "                       ('conv1', nn.Conv2d(1,20,5)),\n",
        "                       ('relu1', nn.ReLU()),\n",
        "                       ('conv2', nn.Conv2d(20, 64, 5)),\n",
        "                       ('relu2', nn.ReLU())\n",
        "]))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymNkOZtW9K9s",
        "outputId": "6df158aa-ee5d-44f9-89cd-39a33b782e9d"
      },
      "source": [
        "for module in layer.modules():\n",
        "    print(module)\n",
        "    #param.requires_grad=True"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu2): ReLU()\n",
            ")\n",
            "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "ReLU()\n",
            "Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "ReLU()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnHGeuy09K9s",
        "outputId": "d903d70c-7bde-4a8d-8a2f-120e644a25bc"
      },
      "source": [
        "for name, param in layer.named_parameters():\n",
        "    print(name,param.requires_grad)\n",
        "    #param.requires_grad=True"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.weight True\n",
            "conv1.bias True\n",
            "conv2.weight True\n",
            "conv2.bias True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYh0_Pne9K9u",
        "outputId": "92d5691e-6ba5-4a38-e607-9739cc6d3067"
      },
      "source": [
        "input_ = torch.randn(1, 1, 124, 124)\n",
        "output = layer(input_)\n",
        "print(output.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 116, 116])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFTxFqrC9K9w"
      },
      "source": [
        "#### append 新的 module到 sequential上"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8na6_EdD9K9w"
      },
      "source": [
        "# import torch.nn as nn\n",
        "\n",
        "# modules = []\n",
        "# modules.append(nn.Conv2d(1,20,5))\n",
        "# modules.append(nn.ReLU())\n",
        "# modules.append(nn.Conv2d(20,64,5))\n",
        "# modules.append(nn.ReLU())\n",
        "\n",
        "# layer = nn.Sequential(*modules)\n",
        "import torch.nn as nn\n",
        "modules = []\n",
        "modules.append(nn.Conv2d(1, 20, 5))\n",
        "modules.append(nn.ReLU())\n",
        "modules.append(nn.Conv2d(20, 64, 5))\n",
        "modules.append(nn.ReLU())\n",
        "\n",
        "layer = nn.Sequential(*modules)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4DXBhaT9K9x",
        "outputId": "cfe7091d-73bd-4591-cf93-83bdc49f2579"
      },
      "source": [
        "layer"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (1): ReLU()\n",
              "  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (3): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTUda1kV9K9x",
        "outputId": "af5a5f38-8f40-4763-9e40-81491a870268"
      },
      "source": [
        "input_ = torch.randn(1, 1, 124, 124)\n",
        "output = layer(input_)\n",
        "print(output.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 116, 116])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ1uPEFc9K9y"
      },
      "source": [
        "* 另一種方式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpfxQJkH9K9y"
      },
      "source": [
        "# layer = torch.nn.Sequential()\n",
        "# layer.add_module(\"conv1\", nn.Conv2d(1,20,5))\n",
        "# layer.add_module(\"relu1\", nn.ReLU())\n",
        "# layer.add_module(\"conv2\", nn.Conv2d(20,64,5))\n",
        "# layer.add_module(\"relu2\", nn.ReLU())\n",
        "layer = torch.nn.Sequential()\n",
        "layer.add_module(\"conv1\", nn.Conv2d(1,20,5))\n",
        "layer.add_module(\"relu1\", nn.ReLU())\n",
        "layer.add_module(\"conv2\", nn.Conv2d(20, 64, 5))\n",
        "layer.add_module(\"conv2\", nn.ReLU())"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbGv6Ujt9K9z",
        "outputId": "bebb295b-4658-48c7-a389-214d211d3159"
      },
      "source": [
        "layer"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu1): ReLU()\n",
              "  (conv2): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRo-_dUC9K90",
        "outputId": "9826b093-46ae-4ba2-8455-aca55561e77e"
      },
      "source": [
        "input_ = torch.randn(1, 1, 124, 124)\n",
        "output = layer(input_)\n",
        "print(output.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 20, 120, 120])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkDcMfRT9K90"
      },
      "source": [
        "## ModuleList\n",
        "* 操作就像是python list, 但其內的module, parameters是可以被追蹤的"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9enCcdP9K91",
        "outputId": "26e634f5-8901-48ec-8b8e-b006f0b48170"
      },
      "source": [
        "# layer = nn.ModuleList()\n",
        "# layer.append(nn.Conv2d(1,20,5))\n",
        "# layer.append(nn.ReLU())\n",
        "# layer.append(nn.Conv2d(20,64,5))\n",
        "# layer.append(nn.ReLU())\n",
        "layer = nn.ModuleList()\n",
        "layer.append(nn.Conv2d(1, 20, 5))\n",
        "layer.append(nn.ReLU())\n",
        "layer.append(nn.Conv2d(20, 64, 5))\n",
        "layer.append(nn.ReLU())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (1): ReLU()\n",
              "  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (3): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra6b_kMn9K91",
        "outputId": "e5341a87-3cb4-4a74-bb49-274067196329"
      },
      "source": [
        "# input_ = torch.randn(1, 1, 124, 124)\n",
        "# for _, module in enumerate(layer):\n",
        "#     if _ == 0:\n",
        "#         output = module(input_)\n",
        "#     else:\n",
        "#         output = module(output)\n",
        "# print(output.shape)\n",
        "input_ = torch.randn(1,1,124, 124)\n",
        "for _, module in enumerate(layer):\n",
        "  if _ == 0:\n",
        "    output = module(input_)\n",
        "  else:\n",
        "    output = module(output)\n",
        "print(output.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 116, 116])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3U1JWd79K92"
      },
      "source": [
        "* 可以追蹤是什麼意思？ nn.Module有辦法去獲取ModuleList裡面的資訊"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lfstfdu9K93"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer = nn.ModuleList()\n",
        "        self.layer.append(nn.Conv2d(1,20,5))\n",
        "        self.layer.append(nn.ReLU())\n",
        "        self.layer.append(nn.Conv2d(20,64,5))\n",
        "        self.layer.append(nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        for module in self.layer:\n",
        "            x = module(x)\n",
        "        return x"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yl9E3Pt9K93"
      },
      "source": [
        "model = Model()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX2cg8Dv9K93",
        "outputId": "1347c7c0-752d-495f-d6a8-b9280d71d9d8"
      },
      "source": [
        "model"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer): ModuleList(\n",
              "    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKWCeGaV9K94",
        "outputId": "558537ef-b9ab-4390-f5af-2ac0145d000a"
      },
      "source": [
        "input_ = torch.randn(1, 1, 124, 124)\n",
        "output = model(input_)\n",
        "print(output.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 116, 116])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEqL3WlP9K95"
      },
      "source": [
        "* 如果是一般的 python list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqQ46kei9K97"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer = []\n",
        "        self.layer.append(nn.Conv2d(1,20,5))\n",
        "        self.layer.append(nn.ReLU())\n",
        "        self.layer.append(nn.Conv2d(20,64,5))\n",
        "        self.layer.append(nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        for module in self.layer:\n",
        "            x = module(x)\n",
        "        return"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP2ihntV9K98"
      },
      "source": [
        "model = Model()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEPd-6vj9K99",
        "outputId": "a890885a-8449-45ba-f3a4-e0e58452fe9a"
      },
      "source": [
        "model"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9TElyw703AT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}