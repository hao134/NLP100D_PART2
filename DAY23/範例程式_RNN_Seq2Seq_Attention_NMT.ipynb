{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "範例程式 RNN_Seq2Seq_Attention_NMT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo2KKWQP-bXk"
      },
      "source": [
        "\n",
        "# 範例 : RNN Seq 2 Seq 加 attention NMT\n",
        "***\n",
        "- 本範例目標是藉由手刻一個 RNN Seq 2 Seq  並且實用在一個簡單的 中翻英的翻譯應用上 以增進學員對課程的了解\n",
        "-- 實做 attention 在 RNN Seq 2 Seq 以更了解　課程內容\n",
        "-- 應用 RNN Seq 2 Seq 加 attention 解決一個機器翻譯的問題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0jhinu6-d5F"
      },
      "source": [
        "# [教學目標]\n",
        "- 了解 最簡單的 attention 機制如何建立 \n",
        "- 了解如何建立一個機器翻譯模型 之後 transformer 課程也會使用 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZwdlUqL-hHR"
      },
      "source": [
        "# [範例重點]\n",
        "\n",
        "- 了解 最簡單的 attention 機制如何建立\n",
        "- 了解如何建立一個機器翻譯模型 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEwOHtiG7FI8",
        "outputId": "03373047-1c8e-409a-ec36-a9eb556d8a4a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Feb  4 07:23:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIlYz6xAQiJf",
        "outputId": "8cc33006-de98-444c-e770-c47afce78292"
      },
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (0.1.94)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.11.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYxAKVwl8r-x"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "\n",
        "import csv\n",
        "import spacy\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mBAWt05-Z9S",
        "outputId": "05db1f32-195b-45f6-ce71-f3978eb5bfc6"
      },
      "source": [
        "# Colab 進行matplotlib繪圖時顯示繁體中文\n",
        "# 下載字體並命名taipei_sans_tc_beta.ttf，移至指定路徑\n",
        "!wget -O taipei_sans_tc_beta.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download\n",
        "!mv taipei_sans_tc_beta.ttf /usr/local/lib/python3.6/dist-packages/matplotlib//mpl-data/fonts/ttf\n",
        "\n",
        "from matplotlib.font_manager import FontProperties\n",
        "import matplotlib.pyplot as plt \n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "import matplotlib.ticker as ticker\n",
        "# 自定義字體變數\n",
        "myfont = FontProperties(fname=r'/usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data/fonts/ttf/taipei_sans_tc_beta.ttf')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-04 07:23:45--  https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.20.101, 74.125.20.139, 74.125.20.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.20.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/h8b8r7miemhessan9abbvfsif9ks4ods/1612423425000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-02-04 07:23:47--  https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/h8b8r7miemhessan9abbvfsif9ks4ods/1612423425000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_\n",
            "Resolving doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)... 74.125.28.132, 2607:f8b0:400e:c04::84\n",
            "Connecting to doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)|74.125.28.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-font-ttf]\n",
            "Saving to: ‘taipei_sans_tc_beta.ttf’\n",
            "\n",
            "taipei_sans_tc_beta     [  <=>               ]  19.70M  48.7MB/s    in 0.4s    \n",
            "\n",
            "2021-02-04 07:23:48 (48.7 MB/s) - ‘taipei_sans_tc_beta.ttf’ saved [20659344]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNTpzUKdCXF9"
      },
      "source": [
        "先連接自己的GOOGLE DRIVE 為了要儲存資料和訓練模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiOECf8zCScV",
        "outputId": "9284661e-9f14-4824-d3eb-bd4cd1dbee74"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFQqhO5lCr8K"
      },
      "source": [
        "機器翻譯的訓練資料來源是從 https://www.manythings.org/anki/ 下載下來的中英翻譯文本\n",
        "\n",
        "Chinese (Mandarin) - English --> cmn-eng.zip (23610)\n",
        "\n",
        "麻煩大家從網路上下載檔案 解壓後檔案名稱叫做 cmn.txt 請放在一個叫做 /data/的子目錄下\n",
        "\n",
        "我們先把他從檔案讀出來"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT_nou-d7_Sp",
        "outputId": "d5e26139-e028-45ba-c9bb-d645dda30187"
      },
      "source": [
        "!wget https://www.manythings.org/anki/cmn-eng.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-04 07:27:18--  https://www.manythings.org/anki/cmn-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 172.67.173.198, 104.21.55.222, 2606:4700:3031::6815:37de, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|172.67.173.198|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1062383 (1.0M) [application/zip]\n",
            "Saving to: ‘cmn-eng.zip’\n",
            "\n",
            "cmn-eng.zip         100%[===================>]   1.01M  2.05MB/s    in 0.5s    \n",
            "\n",
            "2021-02-04 07:27:19 (2.05 MB/s) - ‘cmn-eng.zip’ saved [1062383/1062383]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiwnzJB58D_R",
        "outputId": "52fb546f-c0e4-47bd-8224-90c8996f03eb"
      },
      "source": [
        "!unzip cmn-eng.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cmn-eng.zip\n",
            "  inflating: cmn.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8b89utF8PrE"
      },
      "source": [
        "!mkdir data\n",
        "!mv ./zip/cmn.txt ./data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP8iTP66CaSY",
        "outputId": "51e378e0-90bd-48eb-a8b7-180ea75b0e55"
      },
      "source": [
        "data_dir = './data/'\n",
        "lines = open(data_dir + 'cmn.txt' , encoding='utf-8').read().strip().split('\\n')\n",
        "trnslt_pairs = [[s for s in l.split('\\t')] for l in lines ]\n",
        "print (\"Sample: \" , trnslt_pairs[1000][0:2] )\n",
        "print (\"Total records:\" , len(trnslt_pairs))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample:  ['He was drowned.', '他被淹死了。']\n",
            "Total records: 24360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NUqXgBXC0Eg"
      },
      "source": [
        "# 在這邊開始準備資料\n",
        "\n",
        "## 為了簡化我們的問題在這邊我們特別刪除了不是以\"你我他她\"這幾個中文字開頭的翻譯句\n",
        "\n",
        "## 在剩下的 13039 筆資料中 我們保留 大約各一千筆給 dev 資料集和 testing 資料集\n",
        "\n",
        "## 之後我們把三個資料集以 csv的格式 儲存在 /data/ 目錄下"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPVAgrluCxYU",
        "outputId": "c8deeea5-4c90-4c7a-f1d7-6ee13c4683f5"
      },
      "source": [
        "\n",
        "# create train and validation set\n",
        "# remove sentence not with ['我','你','他','她']\n",
        "\n",
        "trnslt_pairs = [pair for pair in trnslt_pairs if pair[1][0] in ['我','你','他','她']]\n",
        "print (\"Total records after filtering :\" , len(trnslt_pairs))\n",
        "train, test = train_test_split(trnslt_pairs, test_size=0.08)\n",
        "train, val = train_test_split(train, test_size=0.09)\n",
        "print (\"training data:{} , develop data: {} , testing data: {}\".format(len(train),len(val),len(test)))\n",
        "    \n",
        "def write_csv(trn_data, file_path ):\n",
        "    with open(file_path ,'w', newline='', encoding='utf-8') as fout:\n",
        "        writer = csv.writer (fout)\n",
        "        for itm in trn_data: \n",
        "            writer.writerow ([itm[0],itm[1]])\n",
        "            \n",
        "file_path = data_dir + 'train.csv'\n",
        "write_csv(train, file_path )\n",
        "\n",
        "file_path = data_dir + 'val.csv'\n",
        "write_csv(val, file_path )\n",
        "    \n",
        "file_path = data_dir + 'test.csv'\n",
        "write_csv(test, file_path )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total records after filtering : 13420\n",
            "training data:11234 , develop data: 1112 , testing data: 1074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYmbCCZzDbrf"
      },
      "source": [
        "# 使用我們之前介紹過的的 torchtext 來準備訓練資料\n",
        "\n",
        "## 如果對torchtext 不太熟習的人可以回去複習一下\n",
        "\n",
        "## 這邊有用到一個有名的 NLP套件 spacy 幫我們做 英文tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ESQF6X8DhA2"
      },
      "source": [
        "# 下載 spacy 的英文模型 幫我們做tokenize\n",
        "spacy_eng = spacy.load('en_core_web_sm')\n",
        "def tokenize_eng(text):\n",
        "  #清除不需要的字符\n",
        "  text = re.sub(r\"([.!?])\", r\" \\1\", text)\n",
        "  return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
        "\n",
        "TRG = Field(tokenize = tokenize_eng, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n",
        "\n",
        "\n",
        "\n",
        "def tokenize_cmn(text):\n",
        "  #去掉非中文字元\n",
        "  regex = re.compile(r'[^\\u4e00-\\u9fa5A-Za-z0-9]')\n",
        "  text = regex.sub(' ', text)\n",
        "\n",
        "  return [word for word in text if word.strip()]\n",
        "    \n",
        "\n",
        "SRC = Field(tokenize = tokenize_cmn, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            include_lengths = True)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPKJ6rbkDojF"
      },
      "source": [
        "# 使用torchtext TabularDataset 讀資料\n",
        "\n",
        "## 並且分別建立 src and target 的 字元表"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xA2a_emXDlCj",
        "outputId": "57e312ed-40f1-4f46-996c-85d54e2b6df7"
      },
      "source": [
        "train_dataset, dev_dataset, test_dataset = TabularDataset.splits(\n",
        "    path = data_dir , format = 'csv', skip_header = True,\n",
        "    train='train.csv', validation='val.csv', test='test.csv',\n",
        "    fields=[\n",
        "        ('trg', TRG),\n",
        "        ('src', SRC)\n",
        "    ]\n",
        ")\n",
        "SRC.build_vocab(train_dataset, min_freq = 1)\n",
        "TRG.build_vocab(train_dataset, min_freq = 1)\n",
        "\n",
        "print (\"中文語料的字元表長度: \" , len(SRC.vocab) , \", 英文的字元表長度: \" ,len(TRG.vocab))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "中文語料的字元表長度:  2683 , 英文的字元表長度:  4082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehtRj4_EDxbm"
      },
      "source": [
        "# 建立 train valiate test 資料 iterator "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsM0s5zcDtj1"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_dataset, dev_dataset, test_dataset), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_within_batch = True,\n",
        "     sort_key = lambda x : len(x.src),\n",
        "     device = device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx7ouWYrLGnZ"
      },
      "source": [
        "# 這邊是我們的重點 attention 層\n",
        "\n",
        "## 這邊實作的點積 attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkaJG1BkLF2H"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, hidden, encoder_outputs, mask):\n",
        "    # hidden bz , dec_hid_dim\n",
        "    # encoder_outputs src len, bz , enc_hid_dim x 2\n",
        "    # mask bz , src len\n",
        "    \n",
        "    batch_size = encoder_outputs.shape[1]\n",
        "    src_len = encoder_outputs.shape[0]\n",
        "\n",
        "    hidden = hidden.unsqueeze(1) \n",
        "    # hidden unsqueeze bz , 1 , dec_hid_dim\n",
        "\n",
        "    attention = torch.matmul( hidden , encoder_outputs.permute(1, 2, 0)   )\n",
        "    # attention bz, 1 , src len\n",
        "    \n",
        "    attention = attention.squeeze(1)\n",
        "    # squeeze bz , src len\n",
        "\n",
        "    attention = attention.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "    return F.softmax(attention, dim = 1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iDqTn51D1vh"
      },
      "source": [
        "# 這是一個簡單的 以GRU 為底層 bi-directional encoder \n",
        "\n",
        "## 有關RNN部分的概念請參照前章\n",
        "\n",
        "## 我們這邊不多做說明"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYVl3uJdD6Yk"
      },
      "source": [
        "class RNNEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        # 雙向 ＧＲＵ encoder \n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        #src shape [src len, batch size]\n",
        "        #src_len shape [batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded shape [src len, batch size, emb dim]\n",
        "                \n",
        "        # 使用pack_padded_sequence 來壓縮序列        \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n",
        "                \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "\n",
        "        # 使用 pad_packed_sequence 用來展開序列成原本形狀的      \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "            \n",
        "            \n",
        "        #outputs shape [src len, batch size, hid dim * num directions]\n",
        "        #hidden shape [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #hidden 堆疊 [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        #outputs 是最後一層 \n",
        "        \n",
        "        #hidden [-2, :, : ] 是最後一層 forwards RNN \n",
        "        #hidden [-1, :, : ] 是最後一層 backwards RNN\n",
        "        \n",
        "        # hidden 是最後再過一層 dense layer\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        #outputs shape [src len, batch size, enc hid dim * 2]\n",
        "        #hidden shape [batch size, dec hid dim]\n",
        "        \n",
        "        return outputs, hidden"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSqTjCnAIvyL"
      },
      "source": [
        "# 這是一個以GRU 為底層的 RNN decoder.\n",
        "\n",
        "## 請注意最後一個參數 attention\n",
        "\n",
        "## 這是我們的重點 attention, 讓我們在這邊好好的觀察 attention 怎樣接受輸入\n",
        "\n",
        "## 並且怎樣被使用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MegcYbQgIqTj"
      },
      "source": [
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        # 單向 ＧＲＵ decoder \n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "             \n",
        "        #input shape [batch size]\n",
        "        #hidden shape [batch size, dec hid dim]\n",
        "        #encoder_outputs shape [src len, batch size, enc hid dim * 2]\n",
        "        #mask shape [batch size, src len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input shape [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded shape [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "                \n",
        "        #a shape [batch size, src len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        #a shape [batch size, 1, src len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #encoder_outputs shape [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        #weighted shape [batch size, 1, enc hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted shape [1, batch size, enc hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        \n",
        "        #rnn_input shape [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #output shape [seq len, batch size, dec hid dim * n directions]\n",
        "        #hidden shape [n layers * n directions, batch size, dec hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output shape [1, batch size, dec hid dim]\n",
        "        #hidden shape [1, batch size, dec hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        #prediction shape [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDAlNVoSL_K0"
      },
      "source": [
        "# 這邊是我們的 seq 2 seq 模組\n",
        "\n",
        "## 主要的概念之前的章節有介紹\n",
        "\n",
        "## 這邊只有簡單的說明"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo6INNWLLtmg"
      },
      "source": [
        "class Seq2SeqATTN(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #src_len = [batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "                    \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        mask = self.create_mask(src)\n",
        "\n",
        "        #mask = [batch size, src len]\n",
        "                \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state, all encoder hidden states \n",
        "            #  and mask\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWHiSDt8MPX9"
      },
      "source": [
        "# 在這邊先設定關於我們模型的重要參數\n",
        "\n",
        "## 然後將模型建立起來並且初始化權重\n",
        "\n",
        "## 可以觀察一下我們模型結構"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0CwoSV0MLQG",
        "outputId": "e09fb5c9-397e-4503-d41a-b770d2f1156f"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 256 # 注意 encoder hidden layer 設定 必須為 dec 的一半 \n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "LEARNING_RATE = 0.002\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = RNNEncoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = RNNDecoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "model = Seq2SeqATTN(enc, dec, SRC_PAD_IDX, device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "\n",
        "\n",
        "def initial_mdl_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(initial_mdl_weights)\n",
        "print (\"模型全部參數量: {:10,d} \".format(sum(p.numel() for p in model.parameters())))\n",
        "model"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "模型全部參數量:  9,982,194 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqATTN(\n",
              "  (encoder): RNNEncoder(\n",
              "    (embedding): Embedding(2683, 256)\n",
              "    (rnn): GRU(256, 256, bidirectional=True)\n",
              "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): RNNDecoder(\n",
              "    (attention): Attention()\n",
              "    (embedding): Embedding(4082, 256)\n",
              "    (rnn): GRU(768, 512)\n",
              "    (fc_out): Linear(in_features=1280, out_features=4082, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow3jvSRwMj3J"
      },
      "source": [
        "# 這邊是訓練和evalutate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62Lr0hfOMaz3"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src, src_len = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, src_len.cpu() , trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src, src_len = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, src_len.cpu(), trg, 0) #turn off teacher forcing\n",
        "            \n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdINvIcgMqXk"
      },
      "source": [
        "# 訓練設定\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-eUtJPyMpt5",
        "outputId": "10839095-bc91-49fc-8258-653973e44ab1"
      },
      "source": [
        "MAX_EPOCHS = 20\n",
        "CLIP = 1\n",
        "model_dir =  './data/'\n",
        "best_valid_loss = 9999999\n",
        "\n",
        "for epoch in range(MAX_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    torch.save(model.state_dict(), model_dir + 'model-{}.pt'.format(epoch))\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), model_dir + 'best-model.pt')\n",
        "   \n",
        "    print (\"Epoch {} training time: {:.2f} sec Training Loss: {:.3f} , Valiation Loss: {:.3f}\".format( epoch , end_time - start_time , train_loss , valid_loss))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 training time: 5.99 sec Training Loss: 5.327 , Valiation Loss: 5.079\n",
            "Epoch 1 training time: 5.68 sec Training Loss: 4.432 , Valiation Loss: 4.647\n",
            "Epoch 2 training time: 5.70 sec Training Loss: 4.019 , Valiation Loss: 4.474\n",
            "Epoch 3 training time: 5.71 sec Training Loss: 3.547 , Valiation Loss: 4.038\n",
            "Epoch 4 training time: 5.69 sec Training Loss: 3.163 , Valiation Loss: 3.815\n",
            "Epoch 5 training time: 5.64 sec Training Loss: 2.733 , Valiation Loss: 3.661\n",
            "Epoch 6 training time: 5.66 sec Training Loss: 2.364 , Valiation Loss: 3.582\n",
            "Epoch 7 training time: 5.65 sec Training Loss: 2.060 , Valiation Loss: 3.614\n",
            "Epoch 8 training time: 5.65 sec Training Loss: 1.787 , Valiation Loss: 3.525\n",
            "Epoch 9 training time: 5.69 sec Training Loss: 1.586 , Valiation Loss: 3.567\n",
            "Epoch 10 training time: 5.83 sec Training Loss: 1.412 , Valiation Loss: 3.569\n",
            "Epoch 11 training time: 5.72 sec Training Loss: 1.224 , Valiation Loss: 3.642\n",
            "Epoch 12 training time: 5.65 sec Training Loss: 1.058 , Valiation Loss: 3.670\n",
            "Epoch 13 training time: 5.69 sec Training Loss: 0.977 , Valiation Loss: 3.745\n",
            "Epoch 14 training time: 5.75 sec Training Loss: 0.881 , Valiation Loss: 3.722\n",
            "Epoch 15 training time: 5.74 sec Training Loss: 0.814 , Valiation Loss: 3.805\n",
            "Epoch 16 training time: 5.68 sec Training Loss: 0.725 , Valiation Loss: 3.905\n",
            "Epoch 17 training time: 5.72 sec Training Loss: 0.661 , Valiation Loss: 3.957\n",
            "Epoch 18 training time: 5.75 sec Training Loss: 0.620 , Valiation Loss: 4.016\n",
            "Epoch 19 training time: 5.71 sec Training Loss: 0.560 , Valiation Loss: 4.002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZH2ktXnRIoD"
      },
      "source": [
        "# 為了作業我們要先將模型儲存\n",
        "## 將 vocabulaty 也一併存下\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYy6CC2pRIIE"
      },
      "source": [
        "# Save SRC and TRG vocab\n",
        "torch.save(SRC.vocab, model_dir + 'SRC_vocab.pt')\n",
        "torch.save(TRG.vocab, model_dir + 'TRG_vocab.pt')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0KhZ9kwM-Uq"
      },
      "source": [
        "# Evaluate Loss of testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NOqkO96M-0F",
        "outputId": "0e588684-7638-4c04-fc0f-3b987abc2dd5"
      },
      "source": [
        "model.load_state_dict(torch.load(model_dir + 'best-model.pt'))\n",
        "#model.load_state_dict(torch.load(model_dir + 'model-7.pt'))\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 3.768 | Test PPL:  43.310 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmVejlxvNGB6"
      },
      "source": [
        "# 這邊是執行真正的翻譯工作的函式 \n",
        "\n",
        "## 為了讓我們之後可以展現結果和計算BLEU值"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YXpo3e1NKi6"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "\n",
        "    model.eval()\n",
        "        \n",
        "    #if isinstance(sentence, str):\n",
        "    #    nlp = spacy_en = spacy.load('en_core_web_sm')\n",
        "    #    tokens = [token.text.lower() for token in spacy_en(sentence)]\n",
        "    #else:\n",
        "    #    tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [token.lower() for token in sentence]\n",
        "        \n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    \n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor, src_len.cpu())\n",
        "\n",
        "    mask = model.create_mask(src_tensor)\n",
        "        \n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
        "    \n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
        "\n",
        "        attentions[i] = attention\n",
        "            \n",
        "        pred_token = output.argmax(1).item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XUAH1QHNOQD"
      },
      "source": [
        "# 選擇一句來看翻譯結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwDE1_syNTRY",
        "outputId": "71729011-a72d-4a8d-da5d-8d0572c51da8"
      },
      "source": [
        "example_idx =520\n",
        "\n",
        "src = vars(train_dataset.examples[example_idx])['src']\n",
        "trg = vars(train_dataset.examples[example_idx])['trg']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['我', '受', '夠', '了', '在', '餐', '館', '吃', '飯']\n",
            "trg = ['i', \"'m\", 'fed', 'up', 'with', 'eating', 'in', 'restaurants', '.']\n",
            "predicted trg = ['i', 'eat', 'tea', 'for', 'eating', 'in', 'eating', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnohzNs8PiTJ"
      },
      "source": [
        "# BLEU score implementation\n",
        "## BLEU是雙語評估 (Bilingual Evaluation Understudy) 的縮寫。 它測量翻譯質量的方法是與一組選定的人工翻譯結果進行比較，並測量命中該組人工翻譯結果的機械翻譯結果的準確性。 根據用戶的需要和對文本的依賴性，可以用比單個詞彙表（1-gram 或 uni-gram）更長的長度來測量此準確性，例如選擇2-4個字長（2-4 gram）而不會丟失 單詞之間的順序，以衡量機械翻譯對人類翻譯的準確性。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe1mq2p1O3h5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "fbd1d0fa-9a2f-45fa-ee79-7b7030fdeb63"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    \n",
        "    for datum in data:\n",
        "        \n",
        "        src = vars(datum)['src']\n",
        "        trg = vars(datum)['trg']\n",
        "        \n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "        \n",
        "        #cut off <eos> token\n",
        "        pred_trg = pred_trg[:-1]\n",
        "        \n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "        \n",
        "    return bleu_score(pred_trgs, trgs)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-7d9d8b176fbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext.data.metrics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOCT7EzkQP9T"
      },
      "source": [
        "bleu_score = calculate_bleu(test_dataset, SRC, TRG, model, device)\n",
        "\n",
        "print(f'BLEU score = {bleu_score*100:.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwSC6_fdRQEj"
      },
      "source": [
        "!mkdir ./drive/MyDrive/0204_model\n",
        "! mv ./data/* ./drive/MyDrive/0204_model/"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYAyd103FH0l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}