{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "word2vec高速化_作業.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5Pf_RxOIAYv"
      },
      "source": [
        "### 作業目的: 透過實作加速版word2vec Skip-gram模型來更加了解高速版的word2vec\n",
        "\n",
        "本次作業會採用Penn Tree Bank資料及，學員可以在ptb.train.txt中取得訓練文本資料。這次作業可以讓學員練習到以pytorch搭建模型與進行文本資料的前處理\n",
        "\n",
        "PS: 建議學員使用Colab (或可以使用GPU加速的機器)來進行作業，不然訓練會訓練到天荒地老....."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO-a6e2OI5zg"
      },
      "source": [
        "### Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXPU7BI3HNJ6"
      },
      "source": [
        "# # Import libraries for importing files from Google drive to Colab\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# # Authorize Google SDK to access Google Drive from Colab\n",
        "\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2E7yb-qI9Uv"
      },
      "source": [
        "# download = drive.CreateFile({'id': '請自行輸入自己上傳google drive檔案的連結id'})\n",
        "# download.GetContentFile('ptb.train.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKKpFV6GJwhs"
      },
      "source": [
        "### Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjz-fWmbJRPB"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import tqdm\n",
        "import random\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import urllib.request\n",
        "from typing import List\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9xrgPu3KBgJ",
        "outputId": "80b9e975-8b55-446b-9391-3945b373986b"
      },
      "source": [
        "# 讀取資料\n",
        "\n",
        "# Penn Tree Back dataset\n",
        "with open(\"./ptb.train.txt\", encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "    \n",
        "print(f\"Total {len(lines)} lines\")\n",
        "raw_dataset = [line.split() for line in lines]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 42068 lines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAcF_5CQKH_J",
        "outputId": "2d8bc7aa-a128-4c4b-d3bd-d831eb394202"
      },
      "source": [
        "# 查看前5筆\n",
        "raw_dataset[:5]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['aer',\n",
              "  'banknote',\n",
              "  'berlitz',\n",
              "  'calloway',\n",
              "  'centrust',\n",
              "  'cluett',\n",
              "  'fromstein',\n",
              "  'gitano',\n",
              "  'guterman',\n",
              "  'hydro-quebec',\n",
              "  'ipo',\n",
              "  'kia',\n",
              "  'memotec',\n",
              "  'mlx',\n",
              "  'nahb',\n",
              "  'punts',\n",
              "  'rake',\n",
              "  'regatta',\n",
              "  'rubens',\n",
              "  'sim',\n",
              "  'snack-food',\n",
              "  'ssangyong',\n",
              "  'swapo',\n",
              "  'wachter'],\n",
              " ['pierre',\n",
              "  '<unk>',\n",
              "  'N',\n",
              "  'years',\n",
              "  'old',\n",
              "  'will',\n",
              "  'join',\n",
              "  'the',\n",
              "  'board',\n",
              "  'as',\n",
              "  'a',\n",
              "  'nonexecutive',\n",
              "  'director',\n",
              "  'nov.',\n",
              "  'N'],\n",
              " ['mr.',\n",
              "  '<unk>',\n",
              "  'is',\n",
              "  'chairman',\n",
              "  'of',\n",
              "  '<unk>',\n",
              "  'n.v.',\n",
              "  'the',\n",
              "  'dutch',\n",
              "  'publishing',\n",
              "  'group'],\n",
              " ['rudolph',\n",
              "  '<unk>',\n",
              "  'N',\n",
              "  'years',\n",
              "  'old',\n",
              "  'and',\n",
              "  'former',\n",
              "  'chairman',\n",
              "  'of',\n",
              "  'consolidated',\n",
              "  'gold',\n",
              "  'fields',\n",
              "  'plc',\n",
              "  'was',\n",
              "  'named',\n",
              "  'a',\n",
              "  'nonexecutive',\n",
              "  'director',\n",
              "  'of',\n",
              "  'this',\n",
              "  'british',\n",
              "  'industrial',\n",
              "  'conglomerate'],\n",
              " ['a',\n",
              "  'form',\n",
              "  'of',\n",
              "  'asbestos',\n",
              "  'once',\n",
              "  'used',\n",
              "  'to',\n",
              "  'make',\n",
              "  'kent',\n",
              "  'cigarette',\n",
              "  'filters',\n",
              "  'has',\n",
              "  'caused',\n",
              "  'a',\n",
              "  'high',\n",
              "  'percentage',\n",
              "  'of',\n",
              "  'cancer',\n",
              "  'deaths',\n",
              "  'among',\n",
              "  'a',\n",
              "  'group',\n",
              "  'of',\n",
              "  'workers',\n",
              "  'exposed',\n",
              "  'to',\n",
              "  'it',\n",
              "  'more',\n",
              "  'than',\n",
              "  'N',\n",
              "  'years',\n",
              "  'ago',\n",
              "  'researchers',\n",
              "  'reported']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-MgLAZ_ugWm",
        "outputId": "94009933-adc2-4577-c81d-dbe82b441889"
      },
      "source": [
        "class PreProcessor():\n",
        "    '''Function to do preprocess of input corpus\n",
        "    Parameters\n",
        "    -----------\n",
        "    corpus: str\n",
        "        input corpus to be processed\n",
        "    only_word: bool\n",
        "        whether to filter out non-word\n",
        "    min_freq: int\n",
        "        minimum frequency of a word to be kept\n",
        "    do_subsampling: bool\n",
        "        whether to do subsampling\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, only_word: bool=False, min_freq: int=5, do_subsampling: bool=True, t: float=1e-5):\n",
        "        self.only_word = only_word\n",
        "        self.min_freq = min_freq\n",
        "        self.do_subsampling = do_subsampling\n",
        "        self.t = t\n",
        "    \n",
        "    def process(self, corpus: List[str]):\n",
        "        \n",
        "        word_dic = set()\n",
        "        counter = Counter()\n",
        "        processed_sentence = []\n",
        "        \n",
        "        for sentence in corpus:\n",
        "        \n",
        "            #計算字詞頻率\n",
        "            counter.update(sentence)\n",
        "            processed_sentence.append(sentence)\n",
        "    \n",
        "        #移除頻率過小的字詞\n",
        "        word_cnt = dict(filter(lambda x: x[1] > self.min_freq, counter.items()))\n",
        "        \n",
        "        #添加字詞到字典中\n",
        "        self.word2idx = {word: idx for idx, word in enumerate(word_cnt.keys(), 0)}\n",
        "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
        "        \n",
        "        self.word_frequency = word_cnt.copy()\n",
        "        #將文本轉為ID型式與移除文本中頻率過小的文字\n",
        "        self.processed_corpus = [[self.word2idx[word] for word in line if word in self.word2idx] for line in processed_sentence]\n",
        "        self.total_num_words = sum([len(line) for line in self.processed_corpus])\n",
        "        print(f\"Before subsampling: {self.total_num_words} words\")\n",
        "        \n",
        "        # 進行二次採樣(subsampling)\n",
        "        if self.do_subsampling:\n",
        "            self.processed_corpus = [[idx for idx in line if not self.subsampling(idx)] for line in self.processed_corpus]\n",
        "            self.total_num_words = sum([len(line) for line in self.processed_corpus])\n",
        "            counter = Counter([self.idx2word[idx] for line in self.processed_corpus for idx in line])\n",
        "            word_cnt = dict(counter.items())\n",
        "            self.word_frequency = word_cnt.copy()\n",
        "            print(f\"After subsampling: {self.total_num_words} words\")\n",
        "        \n",
        "        self.processed_corpus = [[idx for idx in line] for line in self.processed_corpus if len(line) != 0]\n",
        "        \n",
        "        return self.processed_corpus, self.word2idx, self.idx2word, self.word_frequency, self.total_num_words\n",
        "    \n",
        "    def subsampling(self, idx):\n",
        "        p = self.t / self.word_frequency[self.idx2word[idx]] * self.total_num_words\n",
        "        p_w = math.sqrt(p) + p\n",
        "        return random.uniform(0, 1) < p_w\n",
        "\n",
        "\n",
        "# 進行資料前處理\n",
        "# 這邊我們subsampling的t取1e-4\n",
        "pre_processor = PreProcessor(True, 5, True, 1e-4)\n",
        "corpus, word2idx, idx2word, word2freq, total_num_words = pre_processor.process(raw_dataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before subsampling: 885720 words\n",
            "After subsampling: 448508 words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfDuJuT5Kkvl"
      },
      "source": [
        "### 定義Skip-gram使用的Dataset與collate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DraniEYMKfWl"
      },
      "source": [
        "# 客製化Dataset\n",
        "class SkipGramGetAllDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, corpus, word2freq, word2idx, idx2word, window_size, num_negatives):\n",
        "        self.corpus = corpus\n",
        "        self.word2freq = word2freq\n",
        "        self.word2idx = word2idx\n",
        "        self.idx2word = idx2word\n",
        "        self.window_size = window_size\n",
        "        self.num_negatives = num_negatives\n",
        "        \n",
        "        self.all_targets, self.all_contexts = self._get_all_contexts_targets()\n",
        "        self.all_negatives = self._get_all_negatives()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.all_targets)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        # hint: 這裡我們會返回 目標字詞，上下文，負採樣樣本\n",
        "        return (self.all_targets[idx], self.all_contexts[idx], self.all_negatives[idx])\n",
        "        \n",
        "    \n",
        "    def _get_all_contexts_targets(self):\n",
        "        all_targets = []\n",
        "        all_contexts = []\n",
        "        \n",
        "        for line in self.corpus:\n",
        "            if len(line) < 2*self.window_size + 1:\n",
        "                continue\n",
        "            \n",
        "            # hint: 這邊我們要創建上下文 (考慮window_size)\n",
        "            ### <your code> ###\n",
        "            all_contexts += line[self.window_size:-self.window_size]\n",
        "            \n",
        "            for index in range(self.window_size, len(line) - self.window_size):\n",
        "                # hint: 創建目標字詞\n",
        "                ### <your code> ###\n",
        "                indices = list(range(max(0, index - self.window_size), min(len(line), index + self.window_size + 1)))\n",
        "                indices.remove(index)\n",
        "                all_targets.append([line[idx] for idx in indices])\n",
        "                               \n",
        "        return all_targets, all_contexts\n",
        "                               \n",
        "    \n",
        "    def _get_all_negatives(self):\n",
        "        \n",
        "        # hint: 進行負採樣，若沒頭緒的學員可以參考實作範例\n",
        "        \n",
        "        cur_exists_words = list(self.word2freq.keys())\n",
        "        sampling_weights = [self.word2freq[word]**0.75 for word in self.word2freq]\n",
        "        population = list(range(len(sampling_weights)))\n",
        "        \n",
        "        all_negatives = []\n",
        "        neg_candidate = []\n",
        "        i = 0\n",
        "        for targets in self.all_targets:\n",
        "          negatives = []\n",
        "          while len(negatives) < self.num_negatives:\n",
        "            if i == len(neg_candidate):\n",
        "              neg_candidate = random.choices(population, sampling_weights, k = int(1e5))\n",
        "              neg_candidate = list(map(lambda x: self.word2idx[cur_exists_words[x]], neg_candidate))\n",
        "              i = 0\n",
        "            if neg_candidate[i] not in targets:\n",
        "              negatives.append(neg_candidate[i])\n",
        "            i += 1\n",
        "          all_negatives.append(negatives)\n",
        "        \n",
        "        return all_negatives\n",
        "    \n",
        "# 客製化collate_fn\n",
        "def skipgram_collate(data):\n",
        "    contexts = []\n",
        "    target_negative = []\n",
        "    labels = []\n",
        "    for target, context, negative in data:\n",
        "        # hint: 將目標字詞、上下文與負採樣樣本個別打包\n",
        "      target_negative += [target + negative]\n",
        "      labels += [[1] * len(target) + [0] * len(negative)]\n",
        "      contexts += [context]\n",
        "    \n",
        "    return torch.tensor(contexts), torch.tensor(target_negative), torch.tensor(labels)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s94kJ0lKKzG5"
      },
      "source": [
        "### 定義Skip-gram模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyyQyLxcKpv1"
      },
      "source": [
        "class SkipGram(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embed_size):\n",
        "        super(SkipGram, self).__init__()\n",
        "        \n",
        "        self.in_embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.out_embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        \n",
        "    def forward(self, contexts, targets):\n",
        "        v = self.in_embedding(contexts)\n",
        "        u = self.out_embedding(targets)\n",
        "        \n",
        "        # do dot product to get output\n",
        "        pred = torch.matmul(v[:, None, :], u.permute(0, 2, 1))\n",
        "        \n",
        "        return pred.squeeze(dim=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHZIFz7yK5An"
      },
      "source": [
        "### 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr4sVBd8K10T"
      },
      "source": [
        "# Define hyperparameters\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "verbose = True\n",
        "num_epochs = 100\n",
        "batch_size = 512\n",
        "embed_size = 100\n",
        "lr = 0.01\n",
        "\n",
        "model = SkipGram(len(word2idx), embed_size)\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "    \n",
        "criterion = nn.BCEWithLogitsLoss(reduction = 'mean')\n",
        "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "dataset = SkipGramGetAllDataset(corpus, word2freq, word2idx, idx2word, 1, 5)\n",
        "loader = DataLoader(dataset, batch_size = batch_size, shuffle = True, collate_fn = skipgram_collate)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE28LW2_LB0I",
        "outputId": "61e1c258-8669-459a-d734-a1aeef50d495"
      },
      "source": [
        "# Start training\n",
        "\n",
        "lst_loss = []\n",
        "model.train()\n",
        "for epc in tqdm.tqdm(range(num_epochs)):\n",
        "    batch_loss = 0\n",
        "\n",
        "    for i, (contexts, target_negative, labels) in enumerate(loader, 1):\n",
        "        # hint: 開始訓練前要先將optimizer的梯度歸零\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if use_cuda:\n",
        "            contexts = contexts.cuda()\n",
        "            target_negative = target_negative.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        pred = model(contexts, target_negative)\n",
        "        loss = criterion(pred.float(), labels.float())\n",
        "        batch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i % 500 == 0:\n",
        "            print(f\"Epoch: {epc + 1}/{num_epochs}, Batch: {i+1}/{len(dataset)/batch_size} Loss: {batch_loss / i:.5f}\")\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"Epoch: {epc + 1}/{num_epochs}, Loss: {batch_loss / i:.5f}\")\n",
        "    \n",
        "    lst_loss.append(batch_loss/i)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/100, Batch: 501/714.4609375 Loss: 1.04240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  1%|          | 1/100 [00:02<04:01,  2.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/100, Loss: 0.91126\n",
            "Epoch: 2/100, Batch: 501/714.4609375 Loss: 0.55398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 2/100 [00:04<03:51,  2.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2/100, Loss: 0.55040\n",
            "Epoch: 3/100, Batch: 501/714.4609375 Loss: 0.52762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 3/100 [00:06<03:44,  2.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3/100, Loss: 0.52761\n",
            "Epoch: 4/100, Batch: 501/714.4609375 Loss: 0.51848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 4/100 [00:09<03:43,  2.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4/100, Loss: 0.51863\n",
            "Epoch: 5/100, Batch: 501/714.4609375 Loss: 0.51293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 5/100 [00:11<03:34,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5/100, Loss: 0.51336\n",
            "Epoch: 6/100, Batch: 501/714.4609375 Loss: 0.50903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 6/100 [00:13<03:29,  2.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6/100, Loss: 0.50982\n",
            "Epoch: 7/100, Batch: 501/714.4609375 Loss: 0.50617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 7/100 [00:15<03:25,  2.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7/100, Loss: 0.50724\n",
            "Epoch: 8/100, Batch: 501/714.4609375 Loss: 0.50456\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 8/100 [00:17<03:26,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8/100, Loss: 0.50543\n",
            "Epoch: 9/100, Batch: 501/714.4609375 Loss: 0.50298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 9/100 [00:20<03:23,  2.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9/100, Loss: 0.50410\n",
            "Epoch: 10/100, Batch: 501/714.4609375 Loss: 0.50221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 10/100 [00:22<03:21,  2.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10/100, Loss: 0.50323\n",
            "Epoch: 11/100, Batch: 501/714.4609375 Loss: 0.50143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 11/100 [00:24<03:15,  2.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11/100, Loss: 0.50257\n",
            "Epoch: 12/100, Batch: 501/714.4609375 Loss: 0.50130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 12/100 [00:26<03:10,  2.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12/100, Loss: 0.50204\n",
            "Epoch: 13/100, Batch: 501/714.4609375 Loss: 0.50076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 13/100 [00:29<03:14,  2.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13/100, Loss: 0.50177\n",
            "Epoch: 14/100, Batch: 501/714.4609375 Loss: 0.50039\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 14/100 [00:31<03:09,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14/100, Loss: 0.50158\n",
            "Epoch: 15/100, Batch: 501/714.4609375 Loss: 0.50019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 15/100 [00:33<03:04,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15/100, Loss: 0.50131\n",
            "Epoch: 16/100, Batch: 501/714.4609375 Loss: 0.49993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 16/100 [00:35<03:02,  2.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16/100, Loss: 0.50115\n",
            "Epoch: 17/100, Batch: 501/714.4609375 Loss: 0.49969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 17/100 [00:37<03:03,  2.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17/100, Loss: 0.50099\n",
            "Epoch: 18/100, Batch: 501/714.4609375 Loss: 0.49982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 18/100 [00:39<02:58,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 18/100, Loss: 0.50096\n",
            "Epoch: 19/100, Batch: 501/714.4609375 Loss: 0.49955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 19/100 [00:42<03:00,  2.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19/100, Loss: 0.50070\n",
            "Epoch: 20/100, Batch: 501/714.4609375 Loss: 0.49958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 20/100 [00:44<02:59,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20/100, Loss: 0.50072\n",
            "Epoch: 21/100, Batch: 501/714.4609375 Loss: 0.49943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 21/100 [00:46<02:59,  2.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 21/100, Loss: 0.50059\n",
            "Epoch: 22/100, Batch: 501/714.4609375 Loss: 0.49983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 22/100 [00:48<02:55,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 22/100, Loss: 0.50053\n",
            "Epoch: 23/100, Batch: 501/714.4609375 Loss: 0.49914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 23/100 [00:51<02:50,  2.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 23/100, Loss: 0.50043\n",
            "Epoch: 24/100, Batch: 501/714.4609375 Loss: 0.49947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 24/100 [00:53<02:50,  2.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 24/100, Loss: 0.50044\n",
            "Epoch: 25/100, Batch: 501/714.4609375 Loss: 0.49942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 25/100 [00:55<02:46,  2.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 25/100, Loss: 0.50035\n",
            "Epoch: 26/100, Batch: 501/714.4609375 Loss: 0.49913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 26/100 [00:58<02:48,  2.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 26/100, Loss: 0.50031\n",
            "Epoch: 27/100, Batch: 501/714.4609375 Loss: 0.49909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 27/100 [01:00<02:44,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 27/100, Loss: 0.50013\n",
            "Epoch: 28/100, Batch: 501/714.4609375 Loss: 0.49889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 28/100 [01:02<02:40,  2.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 28/100, Loss: 0.50017\n",
            "Epoch: 29/100, Batch: 501/714.4609375 Loss: 0.49940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 29/100 [01:04<02:36,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 29/100, Loss: 0.50013\n",
            "Epoch: 30/100, Batch: 501/714.4609375 Loss: 0.49902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 30/100 [01:06<02:39,  2.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 30/100, Loss: 0.50011\n",
            "Epoch: 31/100, Batch: 501/714.4609375 Loss: 0.49890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 31/100 [01:09<02:34,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 31/100, Loss: 0.49996\n",
            "Epoch: 32/100, Batch: 501/714.4609375 Loss: 0.49908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 32/100 [01:11<02:30,  2.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 32/100, Loss: 0.50011\n",
            "Epoch: 33/100, Batch: 501/714.4609375 Loss: 0.49906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 33/100 [01:13<02:27,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 33/100, Loss: 0.49998\n",
            "Epoch: 34/100, Batch: 501/714.4609375 Loss: 0.49959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 34/100 [01:15<02:28,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 34/100, Loss: 0.50001\n",
            "Epoch: 35/100, Batch: 501/714.4609375 Loss: 0.49895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 35/100 [01:17<02:24,  2.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 35/100, Loss: 0.49990\n",
            "Epoch: 36/100, Batch: 501/714.4609375 Loss: 0.49919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 36/100 [01:20<02:20,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36/100, Loss: 0.49998\n",
            "Epoch: 37/100, Batch: 501/714.4609375 Loss: 0.49880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 37/100 [01:22<02:18,  2.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 37/100, Loss: 0.49986\n",
            "Epoch: 38/100, Batch: 501/714.4609375 Loss: 0.49899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 38/100 [01:24<02:16,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 38/100, Loss: 0.49982\n",
            "Epoch: 39/100, Batch: 501/714.4609375 Loss: 0.49872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 39/100 [01:26<02:16,  2.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 39/100, Loss: 0.49984\n",
            "Epoch: 40/100, Batch: 501/714.4609375 Loss: 0.49866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 40/100 [01:28<02:11,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 40/100, Loss: 0.49980\n",
            "Epoch: 41/100, Batch: 501/714.4609375 Loss: 0.49862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 41/100 [01:31<02:09,  2.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 41/100, Loss: 0.49977\n",
            "Epoch: 42/100, Batch: 501/714.4609375 Loss: 0.49882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 42/100 [01:33<02:06,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 42/100, Loss: 0.49989\n",
            "Epoch: 43/100, Batch: 501/714.4609375 Loss: 0.49882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 43/100 [01:35<02:06,  2.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 43/100, Loss: 0.49984\n",
            "Epoch: 44/100, Batch: 501/714.4609375 Loss: 0.49872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 44/100 [01:37<02:02,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 44/100, Loss: 0.49982\n",
            "Epoch: 45/100, Batch: 501/714.4609375 Loss: 0.49881\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 45/100 [01:39<02:00,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 45/100, Loss: 0.49975\n",
            "Epoch: 46/100, Batch: 501/714.4609375 Loss: 0.49857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 46/100 [01:42<01:57,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 46/100, Loss: 0.49973\n",
            "Epoch: 47/100, Batch: 501/714.4609375 Loss: 0.49837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 47/100 [01:44<01:58,  2.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 47/100, Loss: 0.49969\n",
            "Epoch: 48/100, Batch: 501/714.4609375 Loss: 0.49887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 48/100 [01:46<01:55,  2.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 48/100, Loss: 0.49967\n",
            "Epoch: 49/100, Batch: 501/714.4609375 Loss: 0.49852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 49/100 [01:48<01:51,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 49/100, Loss: 0.49972\n",
            "Epoch: 50/100, Batch: 501/714.4609375 Loss: 0.49844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 50/100 [01:50<01:47,  2.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 50/100, Loss: 0.49970\n",
            "Epoch: 51/100, Batch: 501/714.4609375 Loss: 0.49866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 51/100 [01:52<01:44,  2.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 51/100, Loss: 0.49959\n",
            "Epoch: 52/100, Batch: 501/714.4609375 Loss: 0.49863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 52/100 [01:55<01:44,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 52/100, Loss: 0.49963\n",
            "Epoch: 53/100, Batch: 501/714.4609375 Loss: 0.49868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 53/100 [01:57<01:42,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 53/100, Loss: 0.49966\n",
            "Epoch: 54/100, Batch: 501/714.4609375 Loss: 0.49859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 54/100 [01:59<01:39,  2.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 54/100, Loss: 0.49961\n",
            "Epoch: 55/100, Batch: 501/714.4609375 Loss: 0.49867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 55/100 [02:01<01:39,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 55/100, Loss: 0.49965\n",
            "Epoch: 56/100, Batch: 501/714.4609375 Loss: 0.49898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 56/100 [02:04<01:38,  2.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 56/100, Loss: 0.49962\n",
            "Epoch: 57/100, Batch: 501/714.4609375 Loss: 0.49859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 57/100 [02:06<01:34,  2.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 57/100, Loss: 0.49964\n",
            "Epoch: 58/100, Batch: 501/714.4609375 Loss: 0.49861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 58/100 [02:08<01:32,  2.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 58/100, Loss: 0.49963\n",
            "Epoch: 59/100, Batch: 501/714.4609375 Loss: 0.49853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 59/100 [02:10<01:30,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 59/100, Loss: 0.49955\n",
            "Epoch: 60/100, Batch: 501/714.4609375 Loss: 0.49862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 60/100 [02:12<01:27,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 60/100, Loss: 0.49963\n",
            "Epoch: 61/100, Batch: 501/714.4609375 Loss: 0.49861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 61/100 [02:15<01:27,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 61/100, Loss: 0.49953\n",
            "Epoch: 62/100, Batch: 501/714.4609375 Loss: 0.49825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 62/100 [02:17<01:25,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 62/100, Loss: 0.49957\n",
            "Epoch: 63/100, Batch: 501/714.4609375 Loss: 0.49860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 63/100 [02:19<01:21,  2.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 63/100, Loss: 0.49958\n",
            "Epoch: 64/100, Batch: 501/714.4609375 Loss: 0.49877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 64/100 [02:21<01:19,  2.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 64/100, Loss: 0.49951\n",
            "Epoch: 65/100, Batch: 501/714.4609375 Loss: 0.49826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 65/100 [02:24<01:18,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 65/100, Loss: 0.49949\n",
            "Epoch: 66/100, Batch: 501/714.4609375 Loss: 0.49858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 66/100 [02:26<01:16,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 66/100, Loss: 0.49957\n",
            "Epoch: 67/100, Batch: 501/714.4609375 Loss: 0.49855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 67/100 [02:28<01:13,  2.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 67/100, Loss: 0.49950\n",
            "Epoch: 68/100, Batch: 501/714.4609375 Loss: 0.49852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 68/100 [02:30<01:10,  2.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 68/100, Loss: 0.49949\n",
            "Epoch: 69/100, Batch: 501/714.4609375 Loss: 0.49855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 69/100 [02:32<01:09,  2.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 69/100, Loss: 0.49946\n",
            "Epoch: 70/100, Batch: 501/714.4609375 Loss: 0.49820\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 70/100 [02:35<01:06,  2.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 70/100, Loss: 0.49943\n",
            "Epoch: 71/100, Batch: 501/714.4609375 Loss: 0.49841\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 71/100 [02:37<01:03,  2.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 71/100, Loss: 0.49954\n",
            "Epoch: 72/100, Batch: 501/714.4609375 Loss: 0.49858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 72/100 [02:39<01:01,  2.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 72/100, Loss: 0.49946\n",
            "Epoch: 73/100, Batch: 501/714.4609375 Loss: 0.49844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 73/100 [02:41<00:58,  2.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 73/100, Loss: 0.49946\n",
            "Epoch: 74/100, Batch: 501/714.4609375 Loss: 0.49818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 74/100 [02:43<00:56,  2.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 74/100, Loss: 0.49935\n",
            "Epoch: 75/100, Batch: 501/714.4609375 Loss: 0.49871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 75/100 [02:45<00:54,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 75/100, Loss: 0.49945\n",
            "Epoch: 76/100, Batch: 501/714.4609375 Loss: 0.49823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 76/100 [02:48<00:51,  2.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 76/100, Loss: 0.49941\n",
            "Epoch: 77/100, Batch: 501/714.4609375 Loss: 0.49850\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 77/100 [02:50<00:49,  2.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 77/100, Loss: 0.49959\n",
            "Epoch: 78/100, Batch: 501/714.4609375 Loss: 0.49815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 78/100 [02:52<00:48,  2.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 78/100, Loss: 0.49947\n",
            "Epoch: 79/100, Batch: 501/714.4609375 Loss: 0.49851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 79/100 [02:54<00:45,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 79/100, Loss: 0.49946\n",
            "Epoch: 80/100, Batch: 501/714.4609375 Loss: 0.49808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 80/100 [02:56<00:43,  2.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 80/100, Loss: 0.49944\n",
            "Epoch: 81/100, Batch: 501/714.4609375 Loss: 0.49874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 81/100 [02:58<00:41,  2.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 81/100, Loss: 0.49948\n",
            "Epoch: 82/100, Batch: 501/714.4609375 Loss: 0.49822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 82/100 [03:01<00:40,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 82/100, Loss: 0.49943\n",
            "Epoch: 83/100, Batch: 501/714.4609375 Loss: 0.49848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 83/100 [03:03<00:38,  2.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 83/100, Loss: 0.49949\n",
            "Epoch: 84/100, Batch: 501/714.4609375 Loss: 0.49829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 84/100 [03:05<00:35,  2.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 84/100, Loss: 0.49940\n",
            "Epoch: 85/100, Batch: 501/714.4609375 Loss: 0.49811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 85/100 [03:07<00:32,  2.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 85/100, Loss: 0.49941\n",
            "Epoch: 86/100, Batch: 501/714.4609375 Loss: 0.49836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 86/100 [03:09<00:30,  2.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 86/100, Loss: 0.49947\n",
            "Epoch: 87/100, Batch: 501/714.4609375 Loss: 0.49840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 87/100 [03:12<00:28,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 87/100, Loss: 0.49942\n",
            "Epoch: 88/100, Batch: 501/714.4609375 Loss: 0.49850\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 88/100 [03:14<00:26,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 88/100, Loss: 0.49936\n",
            "Epoch: 89/100, Batch: 501/714.4609375 Loss: 0.49823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 89/100 [03:16<00:23,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 89/100, Loss: 0.49940\n",
            "Epoch: 90/100, Batch: 501/714.4609375 Loss: 0.49816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 90/100 [03:18<00:21,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 90/100, Loss: 0.49943\n",
            "Epoch: 91/100, Batch: 501/714.4609375 Loss: 0.49830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 91/100 [03:21<00:20,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 91/100, Loss: 0.49940\n",
            "Epoch: 92/100, Batch: 501/714.4609375 Loss: 0.49833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 92/100 [03:23<00:18,  2.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 92/100, Loss: 0.49935\n",
            "Epoch: 93/100, Batch: 501/714.4609375 Loss: 0.49849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 93/100 [03:25<00:15,  2.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 93/100, Loss: 0.49933\n",
            "Epoch: 94/100, Batch: 501/714.4609375 Loss: 0.49793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 94/100 [03:27<00:13,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 94/100, Loss: 0.49928\n",
            "Epoch: 95/100, Batch: 501/714.4609375 Loss: 0.49843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 95/100 [03:30<00:11,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 95/100, Loss: 0.49940\n",
            "Epoch: 96/100, Batch: 501/714.4609375 Loss: 0.49845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 96/100 [03:32<00:09,  2.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 96/100, Loss: 0.49939\n",
            "Epoch: 97/100, Batch: 501/714.4609375 Loss: 0.49840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 97/100 [03:34<00:06,  2.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 97/100, Loss: 0.49937\n",
            "Epoch: 98/100, Batch: 501/714.4609375 Loss: 0.49847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 98/100 [03:37<00:04,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 98/100, Loss: 0.49933\n",
            "Epoch: 99/100, Batch: 501/714.4609375 Loss: 0.49849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 99/100 [03:39<00:02,  2.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 99/100, Loss: 0.49941\n",
            "Epoch: 100/100, Batch: 501/714.4609375 Loss: 0.49829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [03:41<00:00,  2.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100/100, Loss: 0.49948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "y0rt5W2ELLvP",
        "outputId": "dd4e5dc1-456c-47c7-e84d-6b94050f993c"
      },
      "source": [
        "# visualization loss\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(lst_loss, marker='s')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Word2Vec Skip-gram Model')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43pOYRh-MX_F",
        "outputId": "7e64aa0d-567b-4a21-d376-729585853639"
      },
      "source": [
        "#計算字詞相似度\n",
        "\n",
        "def get_similarity(word, top_k, model, word2idx, idx2word):\n",
        "    W = (model.in_embedding.weight.data + model.out_embedding.weight.data) / 2\n",
        "    idx = word2idx.get(word, None)\n",
        "    \n",
        "    if not idx:\n",
        "        # 當出現不在字典中的字詞時，顯示Out of vocabulary error\n",
        "        raise ValueError(\"Out of vocabulary\")\n",
        "    else:\n",
        "        x = W[idx]\n",
        "        \n",
        "        # 使用cosine相似計算字詞間的相似程度\n",
        "        cos = torch.matmul(W, x) / (torch.sum(W * W, dim=-1) * torch.sum(x * x) + 1e-9).sqrt()\n",
        "        _, topk = torch.topk(cos, top_k+1)\n",
        "        \n",
        "        for i in topk[1:]:\n",
        "            print(f\"cosine sim={cos[int(i)]:.3f}: {idx2word[int(i)]}.\")\n",
        "\n",
        "get_similarity('love', 4, model, word2idx, idx2word)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine sim=0.413: equivalent.\n",
            "cosine sim=0.400: fixed-price.\n",
            "cosine sim=0.359: incidents.\n",
            "cosine sim=0.350: bougainville.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_tL9g0oMcCT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}